\documentclass[a4paper,12pt]{article}

\usepackage{fontspec, xunicode, xltxtra}
\usepackage{mathtools}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={210mm,297mm},
 left=5mm,
 right=5mm,
 top=25mm,
 bottom=20mm,
 }



\title{COMP9318: Assignment 1}
\author{Wanze Liu (z5137189)\\
\date{11/04/2019}\\
\large  UNSW\\
\\
\ School of Computer Science and Engineering\\\\
\ Sydney, Australia\\
\\
}


\begin{document}
\maketitle

%------------------------------------------------------------%
\newpage

% ---- Q1(Q)
\section*{Question 1}

% ---- Q1(sol)
\subsection*{1.1}
\setlength{\parindent}{0pt} % Don't indent new paragraphs

\begin{Large}
\begin{center}
\begin{tabular}{llllr}
% \toprule
Location &  Time &  Item &  Quantity \\
% \midrule
ALL &  2006 &       PS2 &    1500 \\
ALL &  2006 &       Wii &     500 \\
ALL &  2006 &       ALL &    2000 \\
ALL &  2005 &       PS2 &    1400 \\
ALL &  2005 &  XBox 360 &    1700 \\
ALL &  2005 &       ALL &    3100 \\
ALL &   ALL &       PS2 &    2900 \\
ALL &   ALL &       Wii &     500 \\
ALL &   ALL &  XBox 360 &    1700 \\
ALL &   ALL &       ALL &    5100 \\
Melbourne &  2005 &  XBox 360 &    1700 \\
Melbourne &  2005 &       ALL &    1700 \\
Melbourne &   ALL &  XBox 360 &    1700 \\
Melbourne &   ALL &       ALL &    1700 \\
Sydney &  2006 &       PS2 &    1500 \\
Sydney &  2006 &       Wii &     500 \\
Sydney &  2006 &       ALL &    2000 \\
Sydney &  2005 &       PS2 &    1400 \\
Sydney &  2005 &       ALL &    1400 \\
Sydney &   ALL &       PS2 &    2900 \\
Sydney &   ALL &       Wii &     500 \\
Sydney &   ALL &       ALL &    3400 \\

% \bottomrule
\end{tabular}
\end{center}
\end{Large}



\subsection*{1.2}

\begin{large}
\begin{flushleft}
SELECT Location, Time, Item, SUM(Quantity)\\
FROM Sales\\
GROUP BY Location, Time, Item\\
UNION ALL\\
SELECT NULL, Time, Item, SUM(Quantity)\\
FROM Sales\\
GROUP BY Time, Item\\
UNION ALL\\
SELECT Location, NULL, Item, SUM(Quantity)\\
FROM Sales\\
GROUP BY Location, Item\\
UNION ALL\\
SELECT Location, Time, NULL, SUM(Quantity)\\
FROM Sales\\
GROUP BY Location, Time\\
UNION ALL\\
SELECT NULL, NULL, Item, SUM(Quantity)\\
FROM Sales\\
GROUP BY Item\\
UNION ALL\\
SELECT NULL, Time, NULL, SUM(Quantity)\\
FROM Sales\\
GROUP BY Time\\
UNION ALL\\
SELECT Location, NULL, NULL, SUM(Quantity)\\
FROM Sales\\
GROUP BY Location\\
UNION ALL\\
SELECT NULL, NULL, NULL, SUM(Quantity)\\
FROM Sales\\
ORDER by Location, Time, desc;\\

\end{flushleft}
\end{large}

\subsection*{1.3}

\begin{Large}
\begin{center}
\begin{tabular}{lrlrlrlr}
Location &  Time &  Item &  Quantity \\

Sydney &  2006 &       ALL &    2000 \\
ALL &   2005 &       ALL &    3100 \\
Sydney &   ALL &       ALL &     3400 \\
Sydney &   ALL &       PS2 &    2900 \\
ALL &   ALL &       PS2 &    2900 \\
ALL &   2006 &       PS2 &    2000 \\
ALL &   ALL &       ALL &    5100\\

\end{tabular}
\end{center}
\end{Large}

\subsection*{1.4}

We have original value mapping :\\
\begin{large}
\begin{center}
\begin{tabular}{llrllrll}

Sydney & 1   &  2005 & 1  &  PS2 & 1\\
Melbourne & 2 \ \ \ \ \ \ \ & 2006 & 2 \ \ \ \ \ \ &  Xbox 360 & 2\\
ALL & 0  &   ALL  & 0  &  wii & 3\\
 {} &{} & {} & {} & ALL & 0   \\

\end{tabular}
\end{center}
\end{large}

I choose the function as \\

\Large $$ f(Location, Time, Item) = Location * 4 * 3 + Time * 4 + Item $$ 



Thus, we transfer the table into\\

\begin{Large}
\begin{center}
\begin{tabular}{lllllrllr}
 Location & Time & Item & Quality & Offset & \\
%\midrule
   0      &  2   &  1   &  1500   &  9     \\
   0      &  2   &  3   &  500   &  11      \\ 
   0      &  2   &  0   &  2000   &  8     \\
   0      &  1   &  1   &  1400   &  5     \\
   0      &  1   &  2   &  1700   &  6       \\
   0      &  1   &  0   &  3100   &  4     \\
   0      &  0   &  1   &  2900   &  1     \\
   0      &  0   &  3   &  500   &  3     \\
   0      &  0   &  2   &  1700   &  2     \\
   0      &  0   &  0   &  5100   &  0      \\
   2      &  1   &  2   &  1700   &  30    \\
   2      &  1   &  0   &  1700   &  28      \\
   2      &  0   &  2   &  1700   &  26      \\
   2      &  0   &  0   &  1700   &  24    \\
   1      &  2   &  1   &  1500   &  21        \\
   1      &  2   &  3   &  500   &  23      \\
   1      &  2   &  0   &  2000   &  20      \\
   1      &  1   &  2   &  1400   &  18       \\
   1      &  1   &  0   &  1400    &  16     \\
   1      &  0   &  2   &  2900   &  14     \\
   1      &  0   &  3   &  500   &  15    \\
   1      &  0   &  0   &  3400   &  12    \\ 
%\midrule
\end{tabular}
\end{center}
\end{Large}



\begin{Large}
\begin{center}
\begin{tabular}{lllll}
%\midrule
Quality & Offset &   Quality & Offset &Dense MD array\\
  1500   &  9   &  5100   &  0   &  5100 \\
  500   &  11    & 2900   &  1  &   2900\\
  2000   &  8   &  1700   &  2     &1700\\
  1400   &  5   &  500   &  3     &500\\
  1700   &  6   &  3100   &  4    & 3100\\
  3100   &  4    & 1400   &  5    & 1400\\
  2900   &  1   &  1700   &  6    &   1700\\
  500   &  3     &  2000   &  8   &  2000\\
  1700   &  2    & 1500   &  9    & 1500\\
  5100   &  0   ========> &  500   &  11  =========> &   500\\ 
  1700   &  30    &  3400   &  12 &   3400\\ 
  1700   &  28    &  2900   &  14 &    2900\\
  1700   &  26    &  500   &  15   & 500\\
  1700   &  24    &  1400    &  16  &  1400 \\
  1500   &  21     &  1400   &  18  &     1400\\
  500   &  23      &  2000   &  20  &    2000\\
  2000   &  20    &  1500   &  21   &     1500\\
  1400   &  18    &  500   &  23    &  500\\
  1400    &  16     &  1700   &  24 &   1700\\
  2900   &  14     &  1700   &  26  &    1700\\
  500   &  15      &  1700   &  28    &  1700\\
  3400   &  12    &  1700   &  30 &   1700\\

%\midrule
\end{tabular}
\end{center}
\end{Large}

\newpage
\section*{Question 2}
\subsection*{2.1}

Based on the Bayes rule , the classifer NB can been wirtten as follow\\
$$ NB(x)=\left\{
\begin{aligned}
1 \ \ , \frac{P(y=1|x)}{P(y=0|x)} \geq 1 \\
0 \ \ , \frac{P(y=1|x)}{P(y=0|x)} < 1 \\
\end{aligned}
\right.
$$

now, We can determine the value of $\frac{P(y=1|x)}{P(y=0|x)}$,according to the formula below\\
$$P(y=1|x) = \frac{P(x|y=1)P(y=1)}{P(x)}$$  
$$P(y=0|x) =\frac{P(x|y=0)P(y=0)}{P(x)} $$

then ,we can get \\
$$\frac{P(y=1|x)}{P(y=0|x)} = \frac{P(x|y=1)P(y=1)}{P(x|y=0)P(y=0)}$$
$$= \frac{P(y=1)\prod\limits_{i=1}^m P(x_i|y=1)}{P(y=0)\prod\limits_{i=1}^n P(x_i|y=0)} $$
$$= \frac{P(y=1)}{P(y=0)} \prod\limits_{i=1}^n \frac{P(x_i|y=1)}{P(x_i|y=0)}$$

We denote $p = P(y=1)$ ,then $1-p = P(y=0)$\\
$a_i = P(x=1 | y=1)$ ,then $1-a_i = P(x=0|y=1)$
\begin{center}
So  ,$P(x_i|y=1)=a_i^{x_i}(1-a_i)^{1-x_i}$\\  
\end{center}
$b_i = P(x=1 | y=0)$ ,then $1-b_i = P(x=0|y=0)$
\begin{center}
And also  ,$P(x_i|y=1)=b_i^{x_i}(1-b_i)^{1-x_i}$\\  
\end{center}
Then , we can get the formula \\
$$\frac{P(x|y=1)P(y=1)}{P(x|y=0)P(y=1)} = \frac{p}{1-p}\prod\limits_{i=1}^n \frac{a_i^{x_i}(1-a_i)^{1-x_i}}{b_i^{x_i}(1-b_i)^{1-x_i}}$$

Then , we apply log caculation on both side of the formula and based on the hind provided , we can get
$$log\frac{P(x|y=1)P(y=1)}{P(x|y=0)P(y=1)} = log(\frac{p}{1-p}\prod\limits_{i=1}^n \frac{a_i^{x_i}(1-a_i)^{1-x_i}}{b_i^{x_i}(1-b_i)^{1-x_i}})$$

$$=log\frac{p}{1-p}+\sum\limits_{i=1}^nlog\frac{a_i^{x_i}(1-a_i)^{1-x_i}}{b_i^{x_i}(1-b_i)^{1-x_i}}$$


$$=log\frac{p}{1-p}+\sum\limits_{i=1}^n log\frac{a_i^{x_i}(1-a_i)^{-x_i}(1-a_i)}{b_i^{x_i}(1-b_i)^{-x_i}(1-b_i)}$$

$$=log\frac{p}{1-p}+\sum\limits_{i=1}^nlog\frac{1-a_i}{1-b_i} + \sum\limits_{i=1}^nx_ilog\frac{(1-b_i)a_i}{(1-a_i)b_i} $$

As we can know $log\frac{p}{1-p}$ and $\sum\limits_{i=1}^nlog\frac{1-a_i}{1-b_i}$ are constant number\\

So , we can get 
$$b = log\frac{p}{1-p} + \sum\limits_{i=1}^nlog\frac{1-a_i}{1-b_i} $$

and
$$w_i = \frac{(1-b_i)a_i}{(1-a_i)b_i} $$

So ,the furmula we deduce below 

$$b + \sum\limits_{i=1}^n w_i x_i $$

which is the liner classifier\\


\newpage
\subsection*{2.2}
It is manily because naive Bayes classifier is simple to do perdicitions by appling the trained value directly, and all of dataset learned independently(caculate the value of $P(x)$ , $P(y)$  , $P(x|y)$ , $ P(y|x)$) , however , Logistic Regression classifier is more sophisticated than naive Bayes ,as it need to full search in data and more training process like Gradient Ascent or Dscent need to be applied to control the accuracy of convergence, and also dataset need to learn jointly, moreover , the data complexity requirement for learning $w_{LR}$ is $O(n)$, while it is $O(log⁡n)$ for learning $w_{NB}$ whcih is smaller than $w_{LR}$.


\section*{question 3}
\subsection*{3.1}
Due to the different pure cotains in the compants,we can write Model:
$$P_{M,j}=\sum\limits_{i=1}^{2}p_{i,j} \cdot q_i $$
according to obervation,the log likelihood function can be written as 
$$\ell(u_j|P_M)=log(\prod\limits_{j=1}^3P(u_j|P_M))$$
$$\Longrightarrow log(\prod_{j=1}^{3} P_{M,j}^{u_j} )$$
$$\Longrightarrow \sum\limits_{j=1}^{3}u_j \cdot log(P_{M,j})) $$
substitute $P_{M,j}$ to the formula,we can get log likelihood function
$$\Longrightarrow \sum\limits_{j=1}^{3}u_j \cdot log(\sum\limits_{i=1}^{2}p_{i,j} \cdot q_i)) $$

\subsection*{3.2}
Due to $q_{1} + q_2 = 1$,Let's find the derivative of $q$ for the log likelihood function:



$$\frac{\partial logP}{\partial q} = \sum\limits_{j=1}^{3}\frac{u_j \cdot (p_{1,j}-p_{2,j})}{p_{2,j} + (p_{1,j}-p_{2,j}) \cdot q}$$

now ,Let the function equal to 0 and substitute observed value to the formula

$$ \frac{0.3 \cdot -0.3}{0.4 - 0.3 \cdot q}+\frac{0.2 \cdot -0.3}{0.5 - 0.3 \cdot q}+\frac{0.5\cdot0.6}{0.1 + 0.6 \cdot q} = 0 $$
$\Longrightarrow q = 0.635155135839922$





So,the MLE of $q1 =  0.635155135839922 $ and $q2 = 0.364844864160078 $

\subsection*{3.3}
Substitute $q_1$ and $q_2$ from above,and we can get
$$u_1 = 0.1\cdot q_1 + 0.4 \cdot q_2$$
$$u_2 = 0.2\cdot q_1 + 0.5 \cdot q_2$$
$$u_3 = 0.7\cdot q_1 + 0.1 \cdot q_2$$
we can deduce

$$u_1= 0.2094534592480234$$
$$u_2= 0.30945345924802337$$
$$u_3= 0.4810930815039532$$


\end{document}

